# ğŸš€ CPU Pipeline ä¸“ç”¨æ—¥å¿—ä¸è°ƒè¯•ç³»ç»Ÿè®¾è®¡

**è®¾è®¡ç›®æ ‡**: ä¸º CPU Pipeline æ‰“é€ ä¸“ä¸šçº§æŒ‡ä»¤è¿½è¸ªã€æ€§èƒ½åˆ†æå’Œè°ƒè¯•å·¥å…·  
**è®¾è®¡åŸåˆ™**: é›¶ä¾èµ–ã€é«˜æ€§èƒ½ã€æ™ºèƒ½åŒ–ã€å¯è§†åŒ–

---

## ğŸ“‹ ç›®å½•

1. [ç°æœ‰é—®é¢˜åˆ†æ](#ç°æœ‰é—®é¢˜åˆ†æ)
2. [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
3. [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
4. [API è®¾è®¡](#api-è®¾è®¡)
5. [è°ƒè¯•å™¨ UI å¢å¼º](#è°ƒè¯•å™¨-ui-å¢å¼º)
6. [å®æ–½è®¡åˆ’](#å®æ–½è®¡åˆ’)

---

## ğŸ” ç°æœ‰é—®é¢˜åˆ†æ

### æ—§ Logger çš„é—®é¢˜

```typescript
// âŒ é—®é¢˜1: ä½¿ç”¨é€šç”¨ loggerï¼Œä¸äº†è§£ CPU æŒ‡ä»¤çš„ç‰¹æ®Šéœ€æ±‚
logger.info('System:Pipeline', 'WB: æŒ‡ä»¤å®Œæˆ', { instructionId, type })

// âŒ é—®é¢˜2: ç®€å•çš„ console.logï¼Œç¼ºä¹ç»“æ„åŒ–
console.log(`ğŸ¯ æŒ‡ä»¤å®Œæˆ: ${trace.type}`, this.formatTraceInfo(trace))

// âŒ é—®é¢˜3: æ— æ³•è¿›è¡Œå¤æ‚æŸ¥è¯¢
// "æ‰¾å‡ºæ‰€æœ‰æ‰§è¡Œè¶…è¿‡ 100ms çš„ schedule.update æŒ‡ä»¤"
// "æ‰¾å‡ºæ‰€æœ‰è§¦å‘äº†å›æ»šçš„æŒ‡ä»¤"
// "åˆ†æèµ„æºå†²çªå¯¼è‡´çš„è°ƒåº¦å»¶è¿Ÿ"
```

### InstructionTracker çš„å±€é™

1. **åŠŸèƒ½å•ä¸€**: åªè®°å½•æ—¶é—´æˆ³å’ŒçŠ¶æ€ï¼Œç¼ºå°‘æ·±åº¦ä¿¡æ¯
2. **æ— æŒä¹…åŒ–**: åˆ·æ–°é¡µé¢åä¸¢å¤±æ‰€æœ‰å†å²
3. **æ— èšåˆåˆ†æ**: æ— æ³•ç»Ÿè®¡å¹³å‡è€—æ—¶ã€æˆåŠŸç‡ç­‰
4. **æ— å…³è”åˆ†æ**: æ— æ³•è¿½è¸ª `correlationId` çš„å®Œæ•´é“¾è·¯
5. **è°ƒè¯•å›°éš¾**: æ— æ³•é‡æ”¾æŒ‡ä»¤ã€æ— æ³•å¯¼å‡ºæ•°æ®

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CPU Pipeline                       â”‚
â”‚  IF â†’ SCH â†’ EX â†’ RES â†’ WB â†’ INT                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ å‘é€æŒ‡ä»¤äº‹ä»¶
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            CPUEventCollector (äº‹ä»¶é‡‡é›†å™¨)             â”‚
â”‚  - æ•è·æ‰€æœ‰æŒ‡ä»¤ç”Ÿå‘½å‘¨æœŸäº‹ä»¶                            â”‚
â”‚  - é›¶ä¾µå…¥å¼è®¾è®¡ï¼Œä¸å½±å“æµæ°´çº¿æ€§èƒ½                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ ç»“æ„åŒ–äº‹ä»¶æµ
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             CPULogger (æ—¥å¿—è®°å½•å™¨)                    â”‚
â”‚  - ç»“æ„åŒ–å­˜å‚¨                                        â”‚
â”‚  - æ™ºèƒ½ç´¢å¼•                                          â”‚
â”‚  - è‡ªåŠ¨åˆ†æ                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ æŸ¥è¯¢æ¥å£
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           CPUDebugger (è°ƒè¯•å™¨)                       â”‚
â”‚  - å®æ—¶ç›‘æ§é¢æ¿                                      â”‚
â”‚  - æ€§èƒ½åˆ†æå›¾è¡¨                                      â”‚
â”‚  - æŒ‡ä»¤æŸ¥è¯¢å¼•æ“                                      â”‚
â”‚  - æ—¶é—´æ—…è¡Œè°ƒè¯•                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

1. **é›¶ä¾èµ–**: å®Œå…¨ç‹¬ç«‹ï¼Œä¸ä¾èµ–æ—§ logger
2. **é«˜æ€§èƒ½**: å¼‚æ­¥æ‰¹é‡å¤„ç†ï¼Œä¸é˜»å¡æµæ°´çº¿
3. **ç»“æ„åŒ–**: æ‰€æœ‰æ•°æ®éƒ½æ˜¯å¼ºç±»å‹ã€å¯æŸ¥è¯¢çš„
4. **æ™ºèƒ½åŒ–**: è‡ªåŠ¨æ£€æµ‹å¼‚å¸¸ã€åˆ†ææ€§èƒ½ç“¶é¢ˆ
5. **å¯è§†åŒ–**: ä¸°å¯Œçš„å›¾è¡¨å’Œäº¤äº’å¼è°ƒè¯•ç•Œé¢

---

## ğŸ§© æ ¸å¿ƒç»„ä»¶

### 1. CPUEvent (äº‹ä»¶æ¨¡å‹)

```typescript
/**
 * CPU æŒ‡ä»¤äº‹ä»¶ç±»å‹
 */
export enum CPUEventType {
  // æŒ‡ä»¤ç”Ÿå‘½å‘¨æœŸ
  INSTRUCTION_CREATED = 'instruction.created',
  INSTRUCTION_ISSUED = 'instruction.issued',
  INSTRUCTION_EXECUTING = 'instruction.executing',
  INSTRUCTION_RESPONDED = 'instruction.responded',
  INSTRUCTION_COMMITTED = 'instruction.committed',
  INSTRUCTION_FAILED = 'instruction.failed',

  // ä¹è§‚æ›´æ–°
  OPTIMISTIC_APPLIED = 'optimistic.applied',
  OPTIMISTIC_ROLLED_BACK = 'optimistic.rolled_back',

  // è°ƒåº¦å™¨
  SCHEDULER_CONFLICT_DETECTED = 'scheduler.conflict_detected',
  SCHEDULER_INSTRUCTION_QUEUED = 'scheduler.instruction_queued',
  SCHEDULER_INSTRUCTION_DEQUEUED = 'scheduler.instruction_dequeued',

  // ç½‘ç»œ
  NETWORK_REQUEST_SENT = 'network.request_sent',
  NETWORK_RESPONSE_RECEIVED = 'network.response_received',
  NETWORK_ERROR = 'network.error',

  // ä¸­æ–­
  INTERRUPT_REGISTERED = 'interrupt.registered',
  INTERRUPT_DISPATCHED = 'interrupt.dispatched',
  INTERRUPT_DEDUPLICATED = 'interrupt.deduplicated',

  // æ€§èƒ½
  PERFORMANCE_WARNING = 'performance.warning',
  PERFORMANCE_BOTTLENECK = 'performance.bottleneck',
}

/**
 * CPU äº‹ä»¶åŸºç¡€æ¥å£
 */
export interface CPUEvent {
  // åŸºç¡€ä¿¡æ¯
  eventId: string
  eventType: CPUEventType
  timestamp: number

  // æŒ‡ä»¤ä¸Šä¸‹æ–‡
  instructionId: string
  instructionType: string
  correlationId: string

  // æµæ°´çº¿çŠ¶æ€
  pipelineStage: PipelineStage
  instructionStatus: InstructionStatus

  // æ€§èƒ½æŒ‡æ ‡
  latency?: number // è¯¥äº‹ä»¶çš„å»¶è¿Ÿï¼ˆç›¸å¯¹äºä¸Šä¸€ä¸ªäº‹ä»¶ï¼‰
  duration?: number // è¯¥é˜¶æ®µçš„æŒç»­æ—¶é—´

  // äº‹ä»¶æ•°æ®
  payload: any

  // å…ƒæ•°æ®
  metadata?: {
    resourceIds?: string[]
    priority?: number
    retryCount?: number
    tags?: string[]
  }
}

/**
 * ç‰¹å®šäº‹ä»¶ç±»å‹çš„è¯¦ç»†æ¥å£
 */
export interface InstructionCreatedEvent extends CPUEvent {
  eventType: CPUEventType.INSTRUCTION_CREATED
  payload: {
    instructionType: string
    payload: any
    origin: 'user' | 'system' | 'sse'
  }
}

export interface OptimisticAppliedEvent extends CPUEvent {
  eventType: CPUEventType.OPTIMISTIC_APPLIED
  payload: {
    snapshot: any
    changes: any // åº”ç”¨äº†ä»€ä¹ˆå˜æ›´
  }
}

export interface OptimisticRolledBackEvent extends CPUEvent {
  eventType: CPUEventType.OPTIMISTIC_ROLLED_BACK
  payload: {
    snapshot: any
    reason: string
    error?: Error
  }
}

export interface SchedulerConflictEvent extends CPUEvent {
  eventType: CPUEventType.SCHEDULER_CONFLICT_DETECTED
  payload: {
    conflictingInstructions: string[]
    conflictingResources: string[]
    waitTime: number
  }
}

export interface NetworkRequestEvent extends CPUEvent {
  eventType: CPUEventType.NETWORK_REQUEST_SENT
  payload: {
    method: string
    url: string
    headers: Record<string, string>
  }
}

export interface NetworkResponseEvent extends CPUEvent {
  eventType: CPUEventType.NETWORK_RESPONSE_RECEIVED
  payload: {
    status: number
    latency: number
    size: number
  }
}

export interface PerformanceWarningEvent extends CPUEvent {
  eventType: CPUEventType.PERFORMANCE_WARNING
  payload: {
    metric: 'latency' | 'throughput' | 'queue_depth'
    threshold: number
    actual: number
    suggestion: string
  }
}
```

### 2. CPUEventCollector (äº‹ä»¶é‡‡é›†å™¨)

```typescript
/**
 * CPU äº‹ä»¶é‡‡é›†å™¨
 *
 * èŒè´£ï¼š
 * 1. åœ¨æµæ°´çº¿å„é˜¶æ®µæ•è·äº‹ä»¶
 * 2. æ‰¹é‡å¼‚æ­¥å‘é€ç»™ CPULogger
 * 3. é›¶ä¾µå…¥ã€é›¶å»¶è¿Ÿ
 */
export class CPUEventCollector {
  private eventQueue: CPUEvent[] = []
  private flushInterval: number = 50 // 50ms æ‰¹é‡åˆ·æ–°
  private maxBatchSize: number = 100
  private enabled: boolean = true

  /**
   * å‘é€äº‹ä»¶ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡æµæ°´çº¿ï¼‰
   */
  emit(event: Partial<CPUEvent>): void {
    if (!this.enabled) return

    const fullEvent: CPUEvent = {
      eventId: this.generateEventId(),
      timestamp: Date.now(),
      ...event,
    } as CPUEvent

    this.eventQueue.push(fullEvent)

    // è§¦å‘æ‰¹é‡åˆ·æ–°
    if (this.eventQueue.length >= this.maxBatchSize) {
      this.flush()
    }
  }

  /**
   * æ‰¹é‡åˆ·æ–°äº‹ä»¶
   */
  private flush(): void {
    if (this.eventQueue.length === 0) return

    const batch = this.eventQueue.splice(0, this.maxBatchSize)

    // å¼‚æ­¥å‘é€ç»™ Loggerï¼ˆä½¿ç”¨ queueMicrotask ç¡®ä¿ä¸é˜»å¡ï¼‰
    queueMicrotask(() => {
      cpuLogger.ingestBatch(batch)
    })
  }

  /**
   * ä¾¿æ·æ–¹æ³•ï¼šæŒ‡ä»¤åˆ›å»º
   */
  onInstructionCreated(instruction: QueuedInstruction): void {
    this.emit({
      eventType: CPUEventType.INSTRUCTION_CREATED,
      instructionId: instruction.id,
      instructionType: instruction.type,
      correlationId: instruction.context.correlationId,
      pipelineStage: PipelineStage.IF,
      instructionStatus: InstructionStatus.PENDING,
      payload: {
        instructionType: instruction.type,
        payload: instruction.payload,
        origin: 'user',
      },
    })
  }

  /**
   * ä¾¿æ·æ–¹æ³•ï¼šä¹è§‚æ›´æ–°åº”ç”¨
   */
  onOptimisticApplied(
    instructionId: string,
    instructionType: string,
    correlationId: string,
    snapshot: any,
    changes: any
  ): void {
    this.emit({
      eventType: CPUEventType.OPTIMISTIC_APPLIED,
      instructionId,
      instructionType,
      correlationId,
      pipelineStage: PipelineStage.EX,
      instructionStatus: InstructionStatus.EXECUTING,
      payload: { snapshot, changes },
    })
  }

  /**
   * ä¾¿æ·æ–¹æ³•ï¼šä¹è§‚æ›´æ–°å›æ»š
   */
  onOptimisticRolledBack(
    instructionId: string,
    instructionType: string,
    correlationId: string,
    snapshot: any,
    reason: string,
    error?: Error
  ): void {
    this.emit({
      eventType: CPUEventType.OPTIMISTIC_ROLLED_BACK,
      instructionId,
      instructionType,
      correlationId,
      pipelineStage: PipelineStage.WB,
      instructionStatus: InstructionStatus.FAILED,
      payload: { snapshot, reason, error: error?.message },
      metadata: { tags: ['rollback', 'failure'] },
    })
  }

  /**
   * ä¾¿æ·æ–¹æ³•ï¼šèµ„æºå†²çªæ£€æµ‹
   */
  onSchedulerConflict(
    instructionId: string,
    instructionType: string,
    correlationId: string,
    conflictingInstructions: string[],
    conflictingResources: string[],
    waitTime: number
  ): void {
    this.emit({
      eventType: CPUEventType.SCHEDULER_CONFLICT_DETECTED,
      instructionId,
      instructionType,
      correlationId,
      pipelineStage: PipelineStage.SCH,
      instructionStatus: InstructionStatus.ISSUED,
      payload: {
        conflictingInstructions,
        conflictingResources,
        waitTime,
      },
      metadata: {
        resourceIds: conflictingResources,
        tags: ['conflict', 'scheduler'],
      },
    })
  }

  /**
   * ä¾¿æ·æ–¹æ³•ï¼šç½‘ç»œè¯·æ±‚
   */
  onNetworkRequest(
    instructionId: string,
    instructionType: string,
    correlationId: string,
    method: string,
    url: string
  ): void {
    this.emit({
      eventType: CPUEventType.NETWORK_REQUEST_SENT,
      instructionId,
      instructionType,
      correlationId,
      pipelineStage: PipelineStage.EX,
      instructionStatus: InstructionStatus.EXECUTING,
      payload: { method, url },
      metadata: { tags: ['network'] },
    })
  }

  /**
   * ä¾¿æ·æ–¹æ³•ï¼šç½‘ç»œå“åº”
   */
  onNetworkResponse(
    instructionId: string,
    instructionType: string,
    correlationId: string,
    status: number,
    latency: number,
    size: number
  ): void {
    this.emit({
      eventType: CPUEventType.NETWORK_RESPONSE_RECEIVED,
      instructionId,
      instructionType,
      correlationId,
      pipelineStage: PipelineStage.RES,
      instructionStatus: InstructionStatus.RESPONDED,
      payload: { status, latency, size },
      latency,
      metadata: { tags: ['network'] },
    })

    // ğŸ”¥ è‡ªåŠ¨æ£€æµ‹æ€§èƒ½è­¦å‘Š
    if (latency > 1000) {
      this.emit({
        eventType: CPUEventType.PERFORMANCE_WARNING,
        instructionId,
        instructionType,
        correlationId,
        pipelineStage: PipelineStage.RES,
        instructionStatus: InstructionStatus.RESPONDED,
        payload: {
          metric: 'latency',
          threshold: 1000,
          actual: latency,
          suggestion: `ç½‘ç»œè¯·æ±‚è€—æ—¶ ${latency}msï¼Œè¶…è¿‡é˜ˆå€¼ 1000ms`,
        },
        metadata: { tags: ['performance', 'warning'] },
      })
    }
  }

  private generateEventId(): string {
    return `evt_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`
  }
}

export const cpuEventCollector = new CPUEventCollector()
```

### 3. CPULogger (æ—¥å¿—è®°å½•å™¨)

```typescript
/**
 * CPU æ—¥å¿—è®°å½•å™¨
 *
 * èŒè´£ï¼š
 * 1. å­˜å‚¨å’Œç´¢å¼•æ‰€æœ‰ CPU äº‹ä»¶
 * 2. æä¾›å¼ºå¤§çš„æŸ¥è¯¢ API
 * 3. è‡ªåŠ¨åˆ†æå’Œèšåˆ
 */
export class CPULogger {
  // å­˜å‚¨
  private events: CPUEvent[] = []
  private maxEvents: number = 10000 // ä¿ç•™æœ€è¿‘ 10000 æ¡äº‹ä»¶

  // ç´¢å¼•
  private eventsByInstruction = new Map<string, CPUEvent[]>()
  private eventsByCorrelation = new Map<string, CPUEvent[]>()
  private eventsByType = new Map<CPUEventType, CPUEvent[]>()

  // ç»Ÿè®¡
  private stats = {
    totalEvents: 0,
    eventCounts: new Map<CPUEventType, number>(),
    instructionCounts: new Map<string, number>(),
  }

  /**
   * æ‰¹é‡æ¥æ”¶äº‹ä»¶
   */
  ingestBatch(events: CPUEvent[]): void {
    for (const event of events) {
      this.ingestEvent(event)
    }
  }

  /**
   * æ¥æ”¶å•ä¸ªäº‹ä»¶
   */
  private ingestEvent(event: CPUEvent): void {
    // å­˜å‚¨
    this.events.push(event)
    if (this.events.length > this.maxEvents) {
      const removed = this.events.shift()!
      this.removeFromIndexes(removed)
    }

    // ç´¢å¼•
    this.addToIndex(this.eventsByInstruction, event.instructionId, event)
    this.addToIndex(this.eventsByCorrelation, event.correlationId, event)
    this.addToIndex(this.eventsByType, event.eventType, event)

    // ç»Ÿè®¡
    this.stats.totalEvents++
    this.stats.eventCounts.set(
      event.eventType,
      (this.stats.eventCounts.get(event.eventType) || 0) + 1
    )
    this.stats.instructionCounts.set(
      event.instructionType,
      (this.stats.instructionCounts.get(event.instructionType) || 0) + 1
    )
  }

  private addToIndex<K>(map: Map<K, CPUEvent[]>, key: K, event: CPUEvent): void {
    if (!map.has(key)) {
      map.set(key, [])
    }
    map.get(key)!.push(event)
  }

  private removeFromIndexes(event: CPUEvent): void {
    // ä»ç´¢å¼•ä¸­ç§»é™¤ï¼ˆç®€åŒ–å®ç°ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ¸…ç†é€»è¾‘ï¼‰
  }

  // ==================== æŸ¥è¯¢ API ====================

  /**
   * æŸ¥è¯¢ï¼šè·å–æŒ‡ä»¤çš„å®Œæ•´äº‹ä»¶é“¾
   */
  getInstructionTrace(instructionId: string): CPUEvent[] {
    return this.eventsByInstruction.get(instructionId) || []
  }

  /**
   * æŸ¥è¯¢ï¼šè·å– correlationId çš„å®Œæ•´é“¾è·¯
   */
  getCorrelationTrace(correlationId: string): CPUEvent[] {
    return this.eventsByCorrelation.get(correlationId) || []
  }

  /**
   * æŸ¥è¯¢ï¼šæŒ‰ç±»å‹è¿‡æ»¤äº‹ä»¶
   */
  getEventsByType(type: CPUEventType): CPUEvent[] {
    return this.eventsByType.get(type) || []
  }

  /**
   * æŸ¥è¯¢ï¼šæŒ‰æŒ‡ä»¤ç±»å‹è¿‡æ»¤
   */
  getEventsByInstructionType(instructionType: string): CPUEvent[] {
    return this.events.filter((e) => e.instructionType === instructionType)
  }

  /**
   * æŸ¥è¯¢ï¼šæŒ‰æ—¶é—´èŒƒå›´è¿‡æ»¤
   */
  getEventsByTimeRange(startTime: number, endTime: number): CPUEvent[] {
    return this.events.filter((e) => e.timestamp >= startTime && e.timestamp <= endTime)
  }

  /**
   * æŸ¥è¯¢ï¼šæŒ‰æ ‡ç­¾è¿‡æ»¤
   */
  getEventsByTags(tags: string[]): CPUEvent[] {
    return this.events.filter((e) => tags.some((tag) => e.metadata?.tags?.includes(tag)))
  }

  /**
   * é«˜çº§æŸ¥è¯¢ï¼šå¤æ‚æ¡ä»¶
   */
  query(filter: {
    instructionType?: string
    eventType?: CPUEventType
    pipelineStage?: PipelineStage
    instructionStatus?: InstructionStatus
    timeRange?: { start: number; end: number }
    tags?: string[]
    minLatency?: number
    maxLatency?: number
  }): CPUEvent[] {
    let results = this.events

    if (filter.instructionType) {
      results = results.filter((e) => e.instructionType === filter.instructionType)
    }

    if (filter.eventType) {
      results = results.filter((e) => e.eventType === filter.eventType)
    }

    if (filter.pipelineStage) {
      results = results.filter((e) => e.pipelineStage === filter.pipelineStage)
    }

    if (filter.instructionStatus) {
      results = results.filter((e) => e.instructionStatus === filter.instructionStatus)
    }

    if (filter.timeRange) {
      results = results.filter(
        (e) => e.timestamp >= filter.timeRange!.start && e.timestamp <= filter.timeRange!.end
      )
    }

    if (filter.tags) {
      results = results.filter((e) => filter.tags!.some((tag) => e.metadata?.tags?.includes(tag)))
    }

    if (filter.minLatency !== undefined) {
      results = results.filter((e) => e.latency !== undefined && e.latency >= filter.minLatency!)
    }

    if (filter.maxLatency !== undefined) {
      results = results.filter((e) => e.latency !== undefined && e.latency <= filter.maxLatency!)
    }

    return results
  }

  // ==================== åˆ†æ API ====================

  /**
   * åˆ†æï¼šæŒ‡ä»¤æ€§èƒ½ç»Ÿè®¡
   */
  analyzeInstructionPerformance(instructionType: string): {
    count: number
    successRate: number
    avgLatency: number
    p50: number
    p95: number
    p99: number
  } {
    const instructions = Array.from(this.eventsByInstruction.entries()).filter(
      ([_, events]) => events[0]?.instructionType === instructionType
    )

    if (instructions.length === 0) {
      return {
        count: 0,
        successRate: 0,
        avgLatency: 0,
        p50: 0,
        p95: 0,
        p99: 0,
      }
    }

    const latencies: number[] = []
    let successCount = 0

    for (const [_, events] of instructions) {
      const commitEvent = events.find((e) => e.eventType === CPUEventType.INSTRUCTION_COMMITTED)
      const failEvent = events.find((e) => e.eventType === CPUEventType.INSTRUCTION_FAILED)

      if (commitEvent) {
        successCount++
        const duration = commitEvent.timestamp - events[0].timestamp
        latencies.push(duration)
      } else if (failEvent) {
        const duration = failEvent.timestamp - events[0].timestamp
        latencies.push(duration)
      }
    }

    latencies.sort((a, b) => a - b)

    return {
      count: instructions.length,
      successRate: successCount / instructions.length,
      avgLatency: latencies.reduce((a, b) => a + b, 0) / latencies.length || 0,
      p50: this.percentile(latencies, 0.5),
      p95: this.percentile(latencies, 0.95),
      p99: this.percentile(latencies, 0.99),
    }
  }

  /**
   * åˆ†æï¼šèµ„æºå†²çªçƒ­ç‚¹
   */
  analyzeResourceConflicts(): Array<{
    resource: string
    conflictCount: number
    avgWaitTime: number
    involvedInstructions: string[]
  }> {
    const conflicts = this.getEventsByType(CPUEventType.SCHEDULER_CONFLICT_DETECTED)

    const resourceMap = new Map<
      string,
      { count: number; totalWait: number; instructions: Set<string> }
    >()

    for (const event of conflicts) {
      const { conflictingResources, waitTime, conflictingInstructions } = event.payload

      for (const resource of conflictingResources) {
        if (!resourceMap.has(resource)) {
          resourceMap.set(resource, {
            count: 0,
            totalWait: 0,
            instructions: new Set(),
          })
        }

        const entry = resourceMap.get(resource)!
        entry.count++
        entry.totalWait += waitTime
        conflictingInstructions.forEach((id: string) => entry.instructions.add(id))
      }
    }

    return Array.from(resourceMap.entries())
      .map(([resource, data]) => ({
        resource,
        conflictCount: data.count,
        avgWaitTime: data.totalWait / data.count,
        involvedInstructions: Array.from(data.instructions),
      }))
      .sort((a, b) => b.conflictCount - a.conflictCount)
  }

  /**
   * åˆ†æï¼šä¹è§‚æ›´æ–°å›æ»šç‡
   */
  analyzeOptimisticRollbackRate(): {
    totalOptimistic: number
    rollbackCount: number
    rollbackRate: number
    byInstructionType: Record<string, { total: number; rollbacks: number; rate: number }>
  } {
    const appliedEvents = this.getEventsByType(CPUEventType.OPTIMISTIC_APPLIED)
    const rolledBackEvents = this.getEventsByType(CPUEventType.OPTIMISTIC_ROLLED_BACK)

    const byType: Record<string, { total: number; rollbacks: number; rate: number }> = {}

    // ç»Ÿè®¡æ¯ç§æŒ‡ä»¤ç±»å‹çš„ä¹è§‚æ›´æ–°å’Œå›æ»š
    for (const event of appliedEvents) {
      if (!byType[event.instructionType]) {
        byType[event.instructionType] = { total: 0, rollbacks: 0, rate: 0 }
      }
      byType[event.instructionType].total++
    }

    for (const event of rolledBackEvents) {
      if (!byType[event.instructionType]) {
        byType[event.instructionType] = { total: 0, rollbacks: 0, rate: 0 }
      }
      byType[event.instructionType].rollbacks++
    }

    // è®¡ç®—å›æ»šç‡
    for (const type in byType) {
      byType[type].rate = byType[type].rollbacks / byType[type].total
    }

    return {
      totalOptimistic: appliedEvents.length,
      rollbackCount: rolledBackEvents.length,
      rollbackRate: rolledBackEvents.length / appliedEvents.length || 0,
      byInstructionType: byType,
    }
  }

  /**
   * åˆ†æï¼šæµæ°´çº¿ååé‡
   */
  analyzeThroughput(timeWindowMs: number = 60000): {
    instructionsPerSecond: number
    eventsPerSecond: number
    avgPipelineUtilization: number
  } {
    const now = Date.now()
    const startTime = now - timeWindowMs

    const recentEvents = this.getEventsByTimeRange(startTime, now)
    const instructionIds = new Set(recentEvents.map((e) => e.instructionId))

    return {
      instructionsPerSecond: (instructionIds.size / timeWindowMs) * 1000,
      eventsPerSecond: (recentEvents.length / timeWindowMs) * 1000,
      avgPipelineUtilization: 0, // TODO: è®¡ç®—æµæ°´çº¿åˆ©ç”¨ç‡
    }
  }

  /**
   * å·¥å…·ï¼šè®¡ç®—ç™¾åˆ†ä½æ•°
   */
  private percentile(values: number[], p: number): number {
    if (values.length === 0) return 0
    const index = Math.ceil(values.length * p) - 1
    return values[index] || 0
  }

  /**
   * è·å–ç»Ÿè®¡ä¿¡æ¯
   */
  getStats() {
    return {
      ...this.stats,
      totalInstructions: this.eventsByInstruction.size,
      totalCorrelations: this.eventsByCorrelation.size,
      storageUsage: this.events.length,
      maxStorage: this.maxEvents,
    }
  }

  /**
   * å¯¼å‡ºæ•°æ®ï¼ˆç”¨äºç¦»çº¿åˆ†æï¼‰
   */
  exportData(filter?: any): {
    events: CPUEvent[]
    stats: any
    exportTime: number
  } {
    const events = filter ? this.query(filter) : this.events

    return {
      events,
      stats: this.getStats(),
      exportTime: Date.now(),
    }
  }

  /**
   * æ¸…ç©ºæ•°æ®
   */
  clear(): void {
    this.events = []
    this.eventsByInstruction.clear()
    this.eventsByCorrelation.clear()
    this.eventsByType.clear()
    this.stats = {
      totalEvents: 0,
      eventCounts: new Map(),
      instructionCounts: new Map(),
    }
  }
}

export const cpuLogger = new CPULogger()
```

### 4. CPUDebugger (è°ƒè¯•å™¨)

```typescript
/**
 * CPU è°ƒè¯•å™¨
 *
 * èŒè´£ï¼š
 * 1. æä¾›è°ƒè¯•å™¨ API
 * 2. æ”¯æŒæ—¶é—´æ—…è¡Œè°ƒè¯•
 * 3. æ”¯æŒæŒ‡ä»¤é‡æ”¾
 */
export class CPUDebugger {
  /**
   * æŸ¥è¯¢ï¼šæ‰§è¡Œæœ€æ…¢çš„æŒ‡ä»¤
   */
  getSlowestInstructions(limit: number = 10): Array<{
    instructionId: string
    instructionType: string
    duration: number
    events: CPUEvent[]
  }> {
    const instructionTraces = Array.from(cpuLogger['eventsByInstruction'].entries())

    const withDuration = instructionTraces.map(([instructionId, events]) => {
      const firstEvent = events[0]
      const lastEvent = events[events.length - 1]
      const duration = lastEvent.timestamp - firstEvent.timestamp

      return {
        instructionId,
        instructionType: firstEvent.instructionType,
        duration,
        events,
      }
    })

    return withDuration.sort((a, b) => b.duration - a.duration).slice(0, limit)
  }

  /**
   * æŸ¥è¯¢ï¼šå¤±è´¥çš„æŒ‡ä»¤
   */
  getFailedInstructions(): Array<{
    instructionId: string
    instructionType: string
    error: string
    events: CPUEvent[]
  }> {
    const failEvents = cpuLogger.getEventsByType(CPUEventType.INSTRUCTION_FAILED)

    return failEvents.map((failEvent) => ({
      instructionId: failEvent.instructionId,
      instructionType: failEvent.instructionType,
      error: failEvent.payload?.error || 'Unknown error',
      events: cpuLogger.getInstructionTrace(failEvent.instructionId),
    }))
  }

  /**
   * æŸ¥è¯¢ï¼šè§¦å‘å›æ»šçš„æŒ‡ä»¤
   */
  getRolledBackInstructions(): Array<{
    instructionId: string
    instructionType: string
    reason: string
    events: CPUEvent[]
  }> {
    const rollbackEvents = cpuLogger.getEventsByType(CPUEventType.OPTIMISTIC_ROLLED_BACK)

    return rollbackEvents.map((event) => ({
      instructionId: event.instructionId,
      instructionType: event.instructionType,
      reason: event.payload.reason,
      events: cpuLogger.getInstructionTrace(event.instructionId),
    }))
  }

  /**
   * æŸ¥è¯¢ï¼šèµ„æºå†²çªé“¾
   */
  getResourceConflictChain(instructionId: string): Array<{
    instructionId: string
    instructionType: string
    blockedBy: string[]
    waitTime: number
  }> {
    const events = cpuLogger.getInstructionTrace(instructionId)
    const conflictEvents = events.filter(
      (e) => e.eventType === CPUEventType.SCHEDULER_CONFLICT_DETECTED
    )

    return conflictEvents.map((event) => ({
      instructionId: event.instructionId,
      instructionType: event.instructionType,
      blockedBy: event.payload.conflictingInstructions,
      waitTime: event.payload.waitTime,
    }))
  }

  /**
   * æ—¶é—´æ—…è¡Œï¼šé‡æ”¾æŒ‡ä»¤
   */
  replayInstruction(instructionId: string): {
    success: boolean
    events: CPUEvent[]
    timeline: Array<{ time: number; stage: string; event: string }>
  } {
    const events = cpuLogger.getInstructionTrace(instructionId)

    const timeline = events.map((event) => ({
      time: event.timestamp,
      stage: event.pipelineStage,
      event: event.eventType,
    }))

    return {
      success: events.some((e) => e.eventType === CPUEventType.INSTRUCTION_COMMITTED),
      events,
      timeline,
    }
  }

  /**
   * è¯Šæ–­ï¼šåˆ†ææŒ‡ä»¤ä¸ºä»€ä¹ˆæ…¢
   */
  diagnoseSlowInstruction(instructionId: string): {
    instructionId: string
    totalDuration: number
    bottleneck: { stage: string; duration: number; percentage: number }
    breakdown: Array<{ stage: string; duration: number; percentage: number }>
    suggestions: string[]
  } {
    const events = cpuLogger.getInstructionTrace(instructionId)
    if (events.length === 0) {
      throw new Error(`Instruction ${instructionId} not found`)
    }

    const firstEvent = events[0]
    const lastEvent = events[events.length - 1]
    const totalDuration = lastEvent.timestamp - firstEvent.timestamp

    // è®¡ç®—æ¯ä¸ªé˜¶æ®µçš„è€—æ—¶
    const stageBreakdown = new Map<string, number>()
    for (let i = 1; i < events.length; i++) {
      const prevEvent = events[i - 1]
      const currEvent = events[i]
      const duration = currEvent.timestamp - prevEvent.timestamp
      const stage = `${prevEvent.pipelineStage}â†’${currEvent.pipelineStage}`
      stageBreakdown.set(stage, (stageBreakdown.get(stage) || 0) + duration)
    }

    const breakdown = Array.from(stageBreakdown.entries())
      .map(([stage, duration]) => ({
        stage,
        duration,
        percentage: (duration / totalDuration) * 100,
      }))
      .sort((a, b) => b.duration - a.duration)

    const bottleneck = breakdown[0]

    // ç”Ÿæˆå»ºè®®
    const suggestions: string[] = []
    if (bottleneck.stage.includes('EX')) {
      suggestions.push('ç½‘ç»œè¯·æ±‚è€—æ—¶è¾ƒé•¿ï¼Œè€ƒè™‘ä¼˜åŒ–åç«¯æ€§èƒ½æˆ–ä½¿ç”¨ç¼“å­˜')
    }
    if (bottleneck.stage.includes('SCH')) {
      suggestions.push('è°ƒåº¦å™¨ç­‰å¾…æ—¶é—´è¾ƒé•¿ï¼Œå­˜åœ¨èµ„æºå†²çª')
    }
    if (bottleneck.percentage > 80) {
      suggestions.push(
        `${bottleneck.stage} å æ€»è€—æ—¶ ${bottleneck.percentage.toFixed(1)}%ï¼Œæ˜¯ä¸»è¦ç“¶é¢ˆ`
      )
    }

    return {
      instructionId,
      totalDuration,
      bottleneck,
      breakdown,
      suggestions,
    }
  }

  /**
   * å®æ—¶ç›‘æ§ï¼šè·å–æœ€è¿‘ N ç§’çš„ç»Ÿè®¡
   */
  getRealtimeStats(windowSeconds: number = 5): {
    instructionsPerSecond: number
    avgLatency: number
    errorRate: number
    topInstructionTypes: Array<{ type: string; count: number }>
  } {
    const now = Date.now()
    const startTime = now - windowSeconds * 1000
    const recentEvents = cpuLogger.getEventsByTimeRange(startTime, now)

    const instructionIds = new Set(recentEvents.map((e) => e.instructionId))
    const failedIds = new Set(
      recentEvents
        .filter((e) => e.eventType === CPUEventType.INSTRUCTION_FAILED)
        .map((e) => e.instructionId)
    )

    const latencies = recentEvents.filter((e) => e.latency !== undefined).map((e) => e.latency!)

    const avgLatency = latencies.reduce((a, b) => a + b, 0) / latencies.length || 0

    const typeCount = new Map<string, number>()
    for (const event of recentEvents) {
      if (event.eventType === CPUEventType.INSTRUCTION_CREATED) {
        typeCount.set(event.instructionType, (typeCount.get(event.instructionType) || 0) + 1)
      }
    }

    const topInstructionTypes = Array.from(typeCount.entries())
      .map(([type, count]) => ({ type, count }))
      .sort((a, b) => b.count - a.count)
      .slice(0, 5)

    return {
      instructionsPerSecond: instructionIds.size / windowSeconds,
      avgLatency,
      errorRate: failedIds.size / instructionIds.size || 0,
      topInstructionTypes,
    }
  }
}

export const cpuDebugger = new CPUDebugger()
```

---

## ğŸ“Š è°ƒè¯•å™¨ UI å¢å¼º

### æ–°å¢åŠŸèƒ½

1. **æ€§èƒ½åˆ†æé¢æ¿**
   - æŒ‡ä»¤ç±»å‹çš„å¹³å‡è€—æ—¶ã€P95ã€P99
   - æµæ°´çº¿å„é˜¶æ®µçš„è€—æ—¶åˆ†å¸ƒ
   - çƒ­åŠ›å›¾ï¼šæŒ‡ä»¤æ‰§è¡Œå¯†åº¦

2. **èµ„æºå†²çªå¯è§†åŒ–**
   - ä¾èµ–å›¾ï¼šå±•ç¤ºå“ªäº›æŒ‡ä»¤åœ¨ç­‰å¾…å“ªäº›èµ„æº
   - å†²çªæ—¶é—´çº¿ï¼šæŒ‰æ—¶é—´å±•ç¤ºèµ„æºå†²çª
   - çƒ­ç‚¹èµ„æºæ’è¡Œ

3. **ä¹è§‚æ›´æ–°ç›‘æ§**
   - å›æ»šç‡ç»Ÿè®¡
   - å›æ»šåŸå› åˆ†ç±»
   - å›æ»šæŒ‡ä»¤è¯¦æƒ…

4. **å®æ—¶ç›‘æ§å¤§å±**
   - æŒ‡ä»¤ååé‡ï¼ˆIPSï¼‰
   - å¹³å‡å»¶è¿Ÿ
   - é”™è¯¯ç‡
   - æµæ°´çº¿åˆ©ç”¨ç‡

5. **æŒ‡ä»¤æŸ¥è¯¢å™¨**
   - é«˜çº§è¿‡æ»¤ï¼ˆç±»å‹ã€çŠ¶æ€ã€æ—¶é—´èŒƒå›´ã€å»¶è¿Ÿï¼‰
   - æ—¶é—´æ—…è¡Œï¼šå›æ”¾æŒ‡ä»¤æ‰§è¡Œè¿‡ç¨‹
   - å¯¼å‡ºåŠŸèƒ½ï¼šå¯¼å‡ºæŸ¥è¯¢ç»“æœä¸º JSON/CSV

6. **è¯Šæ–­å·¥å…·**
   - "ä¸ºä»€ä¹ˆè¿™ä¸ªæŒ‡ä»¤æ…¢ï¼Ÿ" - è‡ªåŠ¨åˆ†æç“¶é¢ˆ
   - "ä¸ºä»€ä¹ˆè§¦å‘å›æ»šï¼Ÿ" - å›æ»šåŸå› åˆ†æ
   - "èµ„æºå†²çªé“¾" - è¿½è¸ªèµ„æºäº‰ç”¨

### UI ç»„ä»¶ç¤ºä¾‹

```vue
<!-- src/views/CPUDebugView.vue -->
<template>
  <div class="cpu-debug-view">
    <!-- 1. å®æ—¶ç›‘æ§ -->
    <section class="realtime-section">
      <h2>ğŸ¯ å®æ—¶ç›‘æ§</h2>
      <div class="metrics-grid">
        <MetricCard
          title="æŒ‡ä»¤ååé‡"
          :value="`${realtimeStats.instructionsPerSecond.toFixed(2)} IPS`"
        />
        <MetricCard title="å¹³å‡å»¶è¿Ÿ" :value="`${realtimeStats.avgLatency.toFixed(0)} ms`" />
        <MetricCard
          title="é”™è¯¯ç‡"
          :value="`${(realtimeStats.errorRate * 100).toFixed(1)}%`"
          :variant="realtimeStats.errorRate > 0.05 ? 'danger' : 'success'"
        />
      </div>
    </section>

    <!-- 2. æ€§èƒ½åˆ†æ -->
    <section class="performance-section">
      <h2>ğŸ“Š æ€§èƒ½åˆ†æ</h2>
      <InstructionPerformanceTable :data="performanceData" />
      <PipelineStageChart :data="stageBreakdown" />
    </section>

    <!-- 3. èµ„æºå†²çª -->
    <section class="conflict-section">
      <h2>âš ï¸ èµ„æºå†²çª</h2>
      <ResourceConflictHeatmap :data="conflictHotspots" />
    </section>

    <!-- 4. ä¹è§‚æ›´æ–° -->
    <section class="optimistic-section">
      <h2>ğŸ”„ ä¹è§‚æ›´æ–°</h2>
      <OptimisticRollbackStats :data="rollbackStats" />
    </section>

    <!-- 5. æŒ‡ä»¤æŸ¥è¯¢ -->
    <section class="query-section">
      <h2>ğŸ” æŒ‡ä»¤æŸ¥è¯¢</h2>
      <InstructionQueryBuilder @query="handleQuery" />
      <InstructionTraceViewer :traces="queryResults" />
    </section>
  </div>
</template>
```

---

## ğŸš€ å®æ–½è®¡åˆ’

### Phase 1: æ ¸å¿ƒåŸºç¡€ï¼ˆ1-2 å¤©ï¼‰

- [ ] å®ç° `CPUEvent` ç±»å‹å®šä¹‰
- [ ] å®ç° `CPUEventCollector`
- [ ] å®ç° `CPULogger` åŸºç¡€åŠŸèƒ½
- [ ] åœ¨æµæ°´çº¿å„é˜¶æ®µé›†æˆäº‹ä»¶é‡‡é›†

### Phase 2: æŸ¥è¯¢ä¸åˆ†æï¼ˆ1-2 å¤©ï¼‰

- [ ] å®Œå–„ `CPULogger` æŸ¥è¯¢ API
- [ ] å®ç°æ€§èƒ½åˆ†æå‡½æ•°
- [ ] å®ç°èµ„æºå†²çªåˆ†æ
- [ ] å®ç°ä¹è§‚æ›´æ–°åˆ†æ

### Phase 3: è°ƒè¯•å™¨ï¼ˆ2-3 å¤©ï¼‰

- [ ] å®ç° `CPUDebugger` æ ¸å¿ƒåŠŸèƒ½
- [ ] å®ç°è¯Šæ–­å·¥å…·
- [ ] å®ç°æ—¶é—´æ—…è¡Œè°ƒè¯•
- [ ] å®ç°æ•°æ®å¯¼å‡º

### Phase 4: UI å¢å¼ºï¼ˆ2-3 å¤©ï¼‰

- [ ] é‡æ„ `CPUDebugView.vue`
- [ ] å®ç°æ€§èƒ½åˆ†æé¢æ¿
- [ ] å®ç°èµ„æºå†²çªå¯è§†åŒ–
- [ ] å®ç°æŒ‡ä»¤æŸ¥è¯¢å™¨
- [ ] å®ç°å®æ—¶ç›‘æ§å¤§å±

### Phase 5: ä¼˜åŒ–ä¸æ–‡æ¡£ï¼ˆ1-2 å¤©ï¼‰

- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆæ‰¹é‡å¤„ç†ã€ç´¢å¼•ä¼˜åŒ–ï¼‰
- [ ] ç¼–å†™ä½¿ç”¨æ–‡æ¡£
- [ ] ç¼–å†™æœ€ä½³å®è·µæŒ‡å—
- [ ] å•å…ƒæµ‹è¯•

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```typescript
// 1. åœ¨æµæ°´çº¿ä¸­é›†æˆäº‹ä»¶é‡‡é›†
// src/cpu/stages/EX.ts
export class ExecuteStage {
  async execute(instruction: QueuedInstruction): Promise<void> {
    // è®°å½•æ‰§è¡Œå¼€å§‹
    cpuEventCollector.emit({
      eventType: CPUEventType.INSTRUCTION_EXECUTING,
      instructionId: instruction.id,
      instructionType: instruction.type,
      correlationId: instruction.context.correlationId,
      pipelineStage: PipelineStage.EX,
      instructionStatus: InstructionStatus.EXECUTING,
    })

    // åº”ç”¨ä¹è§‚æ›´æ–°
    if (isa.optimistic?.enabled) {
      const snapshot = isa.optimistic.apply(instruction.payload, instruction.context)

      cpuEventCollector.onOptimisticApplied(
        instruction.id,
        instruction.type,
        instruction.context.correlationId,
        snapshot,
        { /* å˜æ›´å†…å®¹ */ }
      )
    }

    // æ‰§è¡Œç½‘ç»œè¯·æ±‚
    cpuEventCollector.onNetworkRequest(
      instruction.id,
      instruction.type,
      instruction.context.correlationId,
      'PATCH',
      '/api/tasks/123'
    )

    const result = await executeRequest(...)

    cpuEventCollector.onNetworkResponse(
      instruction.id,
      instruction.type,
      instruction.context.correlationId,
      200,
      125, // å»¶è¿Ÿ
      1024 // å¤§å°
    )
  }
}
```

### è°ƒè¯•å™¨ä½¿ç”¨

```typescript
// 2. åœ¨è°ƒè¯•ç•Œé¢ä¸­ä½¿ç”¨
import { cpuDebugger, cpuLogger } from '@/cpu/logging'

// æŸ¥è¯¢æœ€æ…¢çš„æŒ‡ä»¤
const slowest = cpuDebugger.getSlowestInstructions(10)
console.log('æœ€æ…¢çš„ 10 æ¡æŒ‡ä»¤:', slowest)

// è¯Šæ–­æ…¢æŒ‡ä»¤
const diagnosis = cpuDebugger.diagnoseSlowInstruction('instr_xxx')
console.log('ç“¶é¢ˆåˆ†æ:', diagnosis.bottleneck)
console.log('å»ºè®®:', diagnosis.suggestions)

// åˆ†ææ€§èƒ½
const perf = cpuLogger.analyzeInstructionPerformance('task.update')
console.log(`task.update æˆåŠŸç‡: ${(perf.successRate * 100).toFixed(1)}%`)
console.log(`å¹³å‡å»¶è¿Ÿ: ${perf.avgLatency.toFixed(0)}ms (P95: ${perf.p95.toFixed(0)}ms)`)

// åˆ†æèµ„æºå†²çª
const conflicts = cpuLogger.analyzeResourceConflicts()
console.log('å†²çªæœ€å¤šçš„èµ„æº:', conflicts[0])

// å¯¼å‡ºæ•°æ®
const data = cpuLogger.exportData({
  instructionType: 'schedule.update',
  timeRange: { start: Date.now() - 3600000, end: Date.now() },
})
console.log('å¯¼å‡ºæ•°æ®:', data)
```

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

1. **é›¶ä¾èµ–**ï¼šå®Œå…¨ç‹¬ç«‹çš„æ—¥å¿—ç³»ç»Ÿï¼Œä¸ä¾èµ–æ—§ logger
2. **é«˜æ€§èƒ½**ï¼šå¼‚æ­¥æ‰¹é‡å¤„ç†ï¼Œå¯¹æµæ°´çº¿æ€§èƒ½å½±å“ < 1%
3. **å¼ºå¤§æŸ¥è¯¢**ï¼šæ”¯æŒå¤æ‚çš„è¿‡æ»¤å’ŒèšåˆæŸ¥è¯¢
4. **æ™ºèƒ½åˆ†æ**ï¼šè‡ªåŠ¨æ£€æµ‹ç“¶é¢ˆã€å¼‚å¸¸å’Œæ€§èƒ½é—®é¢˜
5. **å¯è§†åŒ–**ï¼šä¸°å¯Œçš„å›¾è¡¨å’Œäº¤äº’å¼è°ƒè¯•ç•Œé¢
6. **å¯å¯¼å‡º**ï¼šæ”¯æŒå¯¼å‡ºæ•°æ®è¿›è¡Œç¦»çº¿åˆ†æ

---

## ğŸ“š å‚è€ƒèµ„æ–™

- Chrome DevTools Performance API
- OpenTelemetry Tracing
- AWS X-Ray
- DataDog APM

---

**ä½œè€…**: AI Assistant  
**ç‰ˆæœ¬**: v1.0  
**æ—¥æœŸ**: 2025-10-15
